{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9926203f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "ANTHROPIC_API_KEY = <YOUR_API_KEY>\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = ANTHROPIC_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "45bc4149",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_instructions = \"\"\"You are a helpful assistant. Help the user answer any questions.\n",
    "\n",
    "You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "In order to use a tool, you can use <tool></tool> and <tool_input></tool_input> tags. \\\n",
    "You will then get back a response in the form <observation></observation>\n",
    "For example, if you have a tool called 'search' that could run a google search, in order to search for the weather in SF you would respond:\n",
    "\n",
    "<tool>search</tool><tool_input>weather in SF</tool_input>\n",
    "<observation>64 degrees</observation>\n",
    "\n",
    "When you are done, respond with a final answer between <final_answer></final_answer>. For example:\n",
    "\n",
    "<final_answer>The weather in SF is 64 degrees</final_answer>\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {question}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4da4c0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatAnthropic\n",
    "from langchain.prompts import ChatPromptTemplate, AIMessagePromptTemplate\n",
    "from langchain.agents import tool, load_tools, Tool\n",
    "from langchain.utilities import GoogleSerperAPIWrapper\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "working_directory = TemporaryDirectory()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b81e9120",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatAnthropic(model=\"claude-2\",max_tokens_to_sample=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5271f612",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_template(agent_instructions) + AIMessagePromptTemplate.from_template(\"{intermediate_steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "83780d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt_template | model.bind(stop=[\"</tool_input>\", \"</final_answer>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "1e81b05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wget\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: wget\n",
      "  Building wheel for wget (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9657 sha256=f0785863aa63a520c3e2ddcc4bb48c86f19a55585f1026ee8d5c37a708f3b9ae\n",
      "  Stored in directory: /Users/jay/Library/Caches/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
      "Successfully built wget\n",
      "Installing collected packages: wget\n",
      "Successfully installed wget-3.2\n"
     ]
    }
   ],
   "source": [
    "search = GoogleSerperAPIWrapper()\n",
    "!pip install wget\n",
    "import wget\n",
    "\n",
    "import requests\n",
    "\n",
    "from langchain.tools.file_management import (\n",
    "    ReadFileTool,\n",
    "    CopyFileTool,\n",
    "    DeleteFileTool,\n",
    "    MoveFileTool,\n",
    "    WriteFileTool,\n",
    "    ListDirectoryTool,\n",
    ")\n",
    "\n",
    "tool_list = [\n",
    "    Tool(\n",
    "        name=\"search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to ask with search (especially for a research paper)\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"readFile\",\n",
    "        func=ReadFileTool().run,\n",
    "        description=\"useful for when you need to read a file\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"downloadFile\",\n",
    "        func=wget.download,\n",
    "        description=\"useful for when you need to download a file from a url\",\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "from langchain.agents.agent_toolkits import FileManagementToolkit\n",
    "\n",
    "tools = FileManagementToolkit(\n",
    "    root_dir=str(working_directory.name),\n",
    "    selected_tools=[\"read_file\", \"write_file\", \"list_directory\"],\n",
    ").get_tools()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "682f5e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ReadFileTool(name='read_file', description='Read file from disk', args_schema=<class 'langchain.tools.file_management.read.ReadFileInput'>, return_direct=False, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, handle_tool_error=False, root_dir='/var/folders/12/0zyls8316qd2mbd6n28kc9bm0000gn/T/tmpof74j_xr'),\n",
       " WriteFileTool(name='write_file', description='Write file to disk', args_schema=<class 'langchain.tools.file_management.write.WriteFileInput'>, return_direct=False, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, handle_tool_error=False, root_dir='/var/folders/12/0zyls8316qd2mbd6n28kc9bm0000gn/T/tmpof74j_xr'),\n",
       " ListDirectoryTool(name='list_directory', description='List files and directories in a specified folder', args_schema=<class 'langchain.tools.file_management.list_dir.DirectoryListingInput'>, return_direct=False, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, handle_tool_error=False, root_dir='/var/folders/12/0zyls8316qd2mbd6n28kc9bm0000gn/T/tmpof74j_xr')]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "201483db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tool(name='search', description='useful for when you need to ask with search (especially for a research paper)', args_schema=None, return_direct=False, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, handle_tool_error=False, func=<bound method GoogleSerperAPIWrapper.run of GoogleSerperAPIWrapper(k=10, gl='us', hl='en', type='search', tbs=None, serper_api_key='12791d683d28e8c5f696fa10ac9687c7fe73e315', aiosession=None, result_key_for_type={'news': 'news', 'places': 'places', 'images': 'images', 'search': 'organic'})>, coroutine=None),\n",
       " Tool(name='readFile', description='useful for when you need to read a file', args_schema=None, return_direct=False, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, handle_tool_error=False, func=<bound method BaseTool.run of ReadFileTool(name='read_file', description='Read file from disk', args_schema=<class 'langchain.tools.file_management.read.ReadFileInput'>, return_direct=False, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, handle_tool_error=False, root_dir=None)>, coroutine=None),\n",
       " Tool(name='downloadFile', description='useful for when you need to download a file from a url', args_schema=None, return_direct=False, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, handle_tool_error=False, func=<function download at 0x16a2efa30>, coroutine=None)]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "7c5ae25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tools = load_tools([\"google-serper\"], llm=model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "5f0d986f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool, AgentExecutor, BaseSingleActionAgent\n",
    "from typing import List, Tuple, Any, Union\n",
    "from langchain.schema import AgentAction, AgentFinish\n",
    "\n",
    "\n",
    "class AnthropicAgent(BaseSingleActionAgent):\n",
    "    \n",
    "    tools: List[Tool]\n",
    "    chain: Any\n",
    "\n",
    "    @property\n",
    "    def input_keys(self):\n",
    "        return [\"input\"]\n",
    "\n",
    "    def plan(\n",
    "        self, intermediate_steps: List[Tuple[AgentAction, str]], **kwargs: Any\n",
    "    ) -> Union[AgentAction, AgentFinish]:\n",
    "        \"\"\"Given input, decided what to do.\n",
    "\n",
    "        Args:\n",
    "            intermediate_steps: Steps the LLM has taken to date,\n",
    "                along with observations\n",
    "            **kwargs: User inputs.\n",
    "\n",
    "        Returns:\n",
    "            Action specifying what tool to use.\n",
    "        \"\"\"\n",
    "        log = \"\"\n",
    "        for action, observation in intermediate_steps:\n",
    "            log += f\"<tool>{action.tool}</tool><tool_input>{action.tool_input}</tool_input><observation>{observation}</observation>\"\n",
    "        tools = \"\"\n",
    "        for tool in self.tools:\n",
    "            tools += f\"{tool.name}: {tool.description}\\n\"\n",
    "        response = self.chain.invoke({\"intermediate_steps\": log, \"tools\": tools, \"question\": kwargs[\"input\"]})\n",
    "        if \"</tool>\" in response.content:\n",
    "            t, ti = response.content.split(\"</tool>\")\n",
    "            _t = t.split(\"<tool>\")[1]\n",
    "            _ti = ti.split(\"<tool_input>\")[1]\n",
    "            return AgentAction(tool=_t, tool_input=_ti, log=response.content)\n",
    "        elif \"<final_answer>\" in response.content:\n",
    "            t, ti = response.content.split(\"<final_answer>\")\n",
    "            return AgentFinish(return_values={\"output\": ti}, log=response.content)\n",
    "        else:\n",
    "            raise ValueError\n",
    "\n",
    "    async def aplan(\n",
    "        self, intermediate_steps: List[Tuple[AgentAction, str]], **kwargs: Any\n",
    "    ) -> Union[AgentAction, AgentFinish]:\n",
    "        \"\"\"Given input, decided what to do.\n",
    "\n",
    "        Args:\n",
    "            intermediate_steps: Steps the LLM has taken to date,\n",
    "                along with observations\n",
    "            **kwargs: User inputs.\n",
    "\n",
    "        Returns:\n",
    "            Action specifying what tool to use.\n",
    "        \"\"\"\n",
    "        raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "315361c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "\n",
    "\n",
    "agent = AnthropicAgent(tools=tool_list, chain=chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "bca6096f",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(agent=agent, tools=tool_list, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "71b872b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m <tool>search</tool>\n",
      "<tool_input>arxiv GPT-3 paper\u001b[0m\u001b[36;1m\u001b[1;3mSpecifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language ... Cite as: arXiv:2005.14165. This paper provides an introductory survey to GPT-3. We cover some of the historical development behind this technology, some of the key ... In this paper, we test this hypothesis by training a 175 billion parameter autoregressive language model, which we call. GPT-3 ... To conduct a comprehensive analysis of the capabilities of GPT series models, we select six representative models, comprising two GPT-3 series ... Cite as: arXiv:2303.10420. In this paper we explore the capabilities of the most capable GPT-3 model, text-davinci-003, on an established statutory-reasoning dataset ... In this paper, we investigate the few-shot transfer learning abilities of GPT-3 in biomedical. NLP (BioNLP) tasks. This helps to understand whether GPT-3 ... This paper provides an introductory survey to GPT-3. We cover some of the historical development behind this technology, some of the key ... ments multiple times)? [No] Our paper mainly used GPT-3 API with greedy decoding, and there are no randomness for the experiments. An alternative approach is to use a retrieval-augmentation (RetA) method tested in a specific domain. To evaluate LLM performance, OpenAI's GPT- ... GPT-3 achieves strong performance on many NLP datasets, ... While the few-shot results we present in this paper achieve the highest performance,.\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "\n",
      "<tool>downloadFile</tool><tool_input>https://arxiv.org/pdf/2005.14165.pdf\u001b[0m\u001b[38;5;200m\u001b[1;3m2005.14165.pdf\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "\n",
      "<final_answer>The arxiv url of the GPT-3 paper is https://arxiv.org/pdf/2005.14165.pdf. I found the url by searching for \"arxiv GPT-3 paper\", and then downloaded the pdf file.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The arxiv url of the GPT-3 paper is https://arxiv.org/pdf/2005.14165.pdf. I found the url by searching for \"arxiv GPT-3 paper\", and then downloaded the pdf file.'"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.run(\"whats the arxiv url of the GPT-3 paper? Save the file after you find the url.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "cca87246",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4052576605.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[211], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    * check if papers are good\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# BASE TOOLS TO ADD\n",
    "# * check if papers are good\n",
    "# * read pdf as text\n",
    "# * code execution\n",
    "\n",
    "# state variables\n",
    "# * files in directory\n",
    "# * path in folder\n",
    "# * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cdc4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
